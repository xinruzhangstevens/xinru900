{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "pd.set_option('max_colwidth',400)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"F-score is ill-defined and being set to 0.0 due to no predicted samples.\")\n",
    "import re\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"quora-insincere-questions-classification/train.csv\")\n",
    "test = pd.read_csv(\"quora-insincere-questions-classification/test.csv\")\n",
    "sub = pd.read_csv('quora-insincere-questions-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available embeddings: ['glove.840B.300d']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Available embeddings:', os.listdir(\"quora-insincere-questions-classification/embeddings/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  00002165364db923c7e6   \n",
       "1  000032939017120e6e44   \n",
       "2  0000412ca6e4628ce2cf   \n",
       "3  000042bf85aa498cd78e   \n",
       "4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                                                       question_text  \\\n",
       "0           How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                          How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4      Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions in train is 13.\n",
      "Average word length of questions in test is 13.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 71.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^{|}~' + '“”’':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '_`':\n",
    "        x = x.replace(punct, ' ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:09<00:00, 143022.41it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispell_dict={'quora':'quetion and answer website'}\n",
    "# mispell_dict = {'quora' : 'question and answer website',\n",
    "#                 'Quoran':'user' , 'Quorans' : 'user' ,\n",
    "#                 'BITSAT':'exam' , \n",
    "#                 'COMEDK':'exam' , \n",
    "#                 'NMAT':'exam',\n",
    "#                 'KVPY':'exam' , \n",
    "#                 'WBJEE':'exam' , \n",
    "#                 'VITEEE':'exam' , \n",
    "#                 'UCEED':'exam' , \n",
    "#                 'UPSEE':'exam', \n",
    "#                 'AMCAT':'exam',\n",
    "#                 'IITJEE':'exam',\n",
    "#                 'mtech' : 'master of engineering',\n",
    "#                 'articleship' : 'internship',\n",
    "#                 'UPES' : 'University of Petroleum and Energy Studies',\n",
    "#                 'aadhar' : 'identification number',\n",
    "#                 'adhar':'identification number',\n",
    "#                 'marksheet' : 'record tool',\n",
    "#                 'Fortnite' : 'online game',\n",
    "#                 'AFCAT' : 'Air Force Common Admission Test',\n",
    "#                 'bcom' : 'Bachelor of Commerce',\n",
    "#                 'dropshipping' : 'drop shipping',\n",
    "#                 'BNBR' : 'be nice be respectful',\n",
    "#                 'IITian' : 'alumni',\n",
    "#                 'ICOs' : 'inital coin offerings',\n",
    "#                 'L&T':'company',\n",
    "#                 'JIIT':'university',\n",
    "#                 'LNMIIT':'university',\n",
    "#                 'Zerodha':'company',\n",
    "#                 'Kavalireddi':'person',\n",
    "#                 'Binance':'company',\n",
    "#                 'R&D':'research and develop',\n",
    "#                 'etc…':'etc',\n",
    "#                 'Doklam':'area',\n",
    "#                 'AT&T':'company',\n",
    "#                 'NICMAR':'National Institute of Construction Management and Research',\n",
    "#                 'Vajiram':'institue',\n",
    "#                 'fiitjee':'exam',\n",
    "#                 'Unacademy':'company',\n",
    "#                 'D&D':'game',\n",
    "#                 'MUOET':'test',\n",
    "#                 'WooCommerce':'plugin',\n",
    "#                 'INFJs':'acronym',\n",
    "#                 'chsl':'exam',\n",
    "#                 'Modiji':'person',\n",
    "#                 'HackerRank':'web',\n",
    "#                 'AlShamsi':'company',\n",
    "#                 'Q&A':'question and answer',\n",
    "#                 'Bhakts':'a group of people',\n",
    "#                 'bhakts':'a group of people',\n",
    "#                 'Awdhesh':'person',\n",
    "#                 'eLitmus':'company',\n",
    "#                 'J&K':'region',\n",
    "#                 'AIQ':'Artificial Intelligence and Intelligence Quotient',\n",
    "#                 'PUBG':'game',\n",
    "#                 '&amp':'HTML',\n",
    "#                 'CHSL':'exam',\n",
    "#                 'coinbase':'secure platform',\n",
    "#                 'SRMJEE':'exam',\n",
    "#                 'rahu':'astronomical bodies',\n",
    "#                 'h1b':'visa',\n",
    "#                 'Skripal':'person',\n",
    "#                 'SGSITS':'college',\n",
    "#                 'S&P':'stork market index',\n",
    "#                 'jipmer':'exam',\n",
    "#                 'bahubali':'person',\n",
    "#                 'Zebpay':'digital wallet',\n",
    "#                 'MeToo':'movement',\n",
    "#                 'BMSCE':'college',\n",
    "#                 'PDPU':'university',\n",
    "#                 'Whatare':'what are',\n",
    "#                 'Howdo':'how do',\n",
    "#                 'josaa':'Government agency',\n",
    "#                 'SRMJEEE':'exam',\n",
    "#                 'Golang':'program language',\n",
    "#                 'upwork':'platform',\n",
    "#                 'BIPC':'course',\n",
    "#                 'M&A':'Mergers and acquisitions',\n",
    "#                 'MHCET':'exam',\n",
    "#                 'mastrubation':'masturbation',\n",
    "#                 'JBIMS':'university',\n",
    "#                 'arihant':'ship',\n",
    "#                 'CDSE':'exam',\n",
    "#                 'tanx':'tan x',\n",
    "#                 'playstore':'app'\n",
    "#                 }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:01<00:00, 927073.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize: change word into index based on the words' frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 120000\n",
    "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
    "tk.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
    "test_tokenized = tk.texts_to_sequences(test['question_text'].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
    "plt.yscale('log');\n",
    "plt.title('Distribution of question text length in characters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 72\n",
    "maxlen = 72\n",
    "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
    "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=10).split(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peihong/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "embed_size = 300\n",
    "embedding_path = \"quora-insincere-questions-classification/embDict/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\"\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n",
    "all_embs = np.stack(embedding_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net structure (most important part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single LSTM model structure contains several steps:\n",
    "1. embedding\n",
    "2. lstm\n",
    "3. pooling(max and mean)\n",
    "4. linear\n",
    "5. dropout\n",
    "6. linear\n",
    "\n",
    "In class NeuralNet, function **\\_\\_init\\_\\_()**  initializes all the layers we need. Function  **forward()**  shows the structure of our model.\n",
    "\n",
    "To test what are the output shape of every layer, simply add print() method in the **forward()** function and run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        hidden_size = 128\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)# 120000, 300\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))#[120001, 300]\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(512, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x) #[512, 72, 300]\n",
    "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))#[512, 72, 300]\n",
    "        h_lstm, _ = self.lstm(h_embedding)#[512, 72, 256]\n",
    "        avg_pool = torch.mean(h_lstm, 1)#[512, 256]\n",
    "        max_pool, _ = torch.max(h_lstm, 1)#[512, 256]\n",
    "        conc = torch.cat((avg_pool, max_pool), 1)#[512, 512]\n",
    "        conc = self.relu(self.linear(conc))#[512, 16]\n",
    "        conc = self.dropout(conc)#[512, 16]\n",
    "        out = self.out(conc)#[512, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for training a model is always the same, first we have to initialize our model as well as a optimizer and a loss function, then we put the data into the model (epoch and batch), then backward and optimizer.step(), finaly get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_val, y_val, validate=True):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    valid = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')#.cuda()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            \n",
    "        model.eval() # this is to let the model change to the evaluation version, which means after run this code, \n",
    "                     # the parameters will be locked, and all the following code can not change them.\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#----------------------------------Skip these codes below in this cell---------------------------------\n",
    "# These codes are just author's one way to use f1-score to calculate the accuracy. Since it's not as much\n",
    "# important as how to use torch to write a net, it's highly recommended to skip this part.\n",
    "        valid_preds = np.zeros((x_val_fold.size(0)))\n",
    "        \n",
    "        if validate:\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "                y_pred = model(x_batch).detach()\n",
    "\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "            search_result = threshold_search(y_val.cpu().numpy(), valid_preds)\n",
    "\n",
    "            val_f1, val_threshold = search_result['f1'], search_result['threshold']\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} best_t={:.2f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_f1, val_threshold, elapsed_time))\n",
    "        else:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "    valid_preds = np.zeros((x_val_fold.size(0)))\n",
    "    \n",
    "    avg_val_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    print('Validation loss: ', avg_val_loss)\n",
    "\n",
    "    test_preds = np.zeros((len(test_loader.dataset)))\n",
    "    \n",
    "    for i, (x_batch,) in enumerate(test_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "\n",
    "        test_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "    \n",
    "    return valid_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cuda = torch.tensor(X_test, dtype=torch.long)#.cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "batch_size = 512\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell, this is f1-score function part.\n",
    "seed=1029\n",
    "\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n",
    "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
    "    return search_result\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed(seed)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/5 \t loss=0.1461 \t val_loss=0.1121 \t val_f1=0.6358 best_t=0.28 \t time=2106.24s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e19e5d2c39ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#model.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvalid_preds_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_preds_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-adf5ef7eef37>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_val, y_val, validate)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model now!\n",
    "train_preds = np.zeros(len(train))\n",
    "test_preds = np.zeros((len(test), len(splits)))\n",
    "n_epochs = 5\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
    "    x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.long)#.cuda()\n",
    "    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32)#.cuda()\n",
    "    x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.long)#.cuda()\n",
    "    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32)#.cuda()\n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f'Fold {i + 1}')\n",
    "    \n",
    "    seed_everything(seed + i)\n",
    "    model = NeuralNet()\n",
    "    #model.cuda()\n",
    "\n",
    "    valid_preds_fold, test_preds_fold = train_model(model,x_train_fold,y_train_fold,x_val_fold,y_val_fold, validate=True)\n",
    "\n",
    "    train_preds[valid_idx] = valid_preds_fold\n",
    "    test_preds[:, i] = test_preds_fold\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = threshold_search(y_train, train_preds)\n",
    "sub['prediction'] = test_preds.mean(1) > search_result['threshold']\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
